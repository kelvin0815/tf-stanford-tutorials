{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Improving the accuracy of our logistic regression on MNIST\n",
    "\n",
    "We got the accuracy of ~90% on our MNIST dataset with our vanilla model, which is\n",
    "unacceptable. \n",
    "\n",
    "The dataset is basically solved and state of the art models <a href=\"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\">reach accuracies above\n",
    "99%</a> . \n",
    "\n",
    "You can use whatever loss functions, optimizers, even models that you want, as long as\n",
    "your model is built in TensorFlow. \n",
    "\n",
    "You can save your code in the file q2.py. In the comments,\n",
    "explain what you decided to do, instruction on how to run your code, and report your results.\n",
    "\n",
    "Iâ€™m happy if you can reach 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Approach: Three-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Params\n",
    "numTrainingSamples = mnist.train.images.shape[0] # 55000\n",
    "numFeatures = mnist.train.images.shape[1] # 784\n",
    "numClasses = mnist.train.labels.shape[1] # 10\n",
    "\n",
    "# Network Params\n",
    "numHiddenUnits1 = 200\n",
    "numHiddenUnits2 = 200\n",
    "numHiddenUnits3 = 200\n",
    "numEpochs = 10000\n",
    "batchSize = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, numFeatures])\n",
    "y = tf.placeholder(tf.float32, shape=[None, numClasses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_weight(inputDim, outputDim):\n",
    "    return tf.Variable(tf.truncated_normal([inputDim, outputDim], stddev=0.1, seed=1))\n",
    "\n",
    "def layer_bias(dim):\n",
    "    return tf.Variable(tf.constant(0.1), [dim])\n",
    "\n",
    "def network_layer(layerInput, weight, bias):\n",
    "    layerOutput = tf.nn.relu(tf.matmul(layerInput, weight) + bias)\n",
    "    return layerOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden1': layer_weight(numFeatures, numHiddenUnits1),\n",
    "    'hidden2': layer_weight(numHiddenUnits1, numHiddenUnits2),\n",
    "    'hidden3': layer_weight(numHiddenUnits2, numHiddenUnits3),\n",
    "    'output': layer_weight(numHiddenUnits3, numClasses)\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden1': layer_bias(numHiddenUnits1),\n",
    "    'hidden2': layer_bias(numHiddenUnits2),\n",
    "    'hidden3': layer_bias(numHiddenUnits3),\n",
    "    'output': layer_bias(numClasses),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hiddenLayer1Output = network_layer(X, weights['hidden1'], biases['hidden1'])\n",
    "hiddenLayer2Output = network_layer(hiddenLayer1Output, weights['hidden2'], biases['hidden2'])\n",
    "hiddenLayer3Output = network_layer(hiddenLayer2Output, weights['hidden3'], biases['hidden3'])\n",
    "finalOutput = network_layer(hiddenLayer3Output, weights['output'], biases['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(finalOutput,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=finalOutput\n",
    "    )\n",
    ")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training accuracy: 0.24\n",
      "Iteration 2, training accuracy: 0.26\n",
      "Iteration 3, training accuracy: 0.29\n",
      "Iteration 4, training accuracy: 0.305\n",
      "Iteration 5, training accuracy: 0.31\n",
      "Iteration 6, training accuracy: 0.41\n",
      "Iteration 7, training accuracy: 0.41\n",
      "Iteration 8, training accuracy: 0.435\n",
      "Iteration 9, training accuracy: 0.45\n",
      "Iteration 1000, training accuracy: 0.97\n",
      "Iteration 2000, training accuracy: 0.975\n",
      "Iteration 3000, training accuracy: 0.99\n",
      "Iteration 4000, training accuracy: 1.0\n",
      "Iteration 5000, training accuracy: 0.995\n",
      "Iteration 6000, training accuracy: 1.0\n",
      "Iteration 7000, training accuracy: 0.995\n",
      "Iteration 8000, training accuracy: 1.0\n",
      "Iteration 9000, training accuracy: 1.0\n",
      "Iteration 10000, training accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(numEpochs):\n",
    "    batch = mnist.train.next_batch(batch_size=batchSize)\n",
    "    sess.run(optimizer, feed_dict={X: batch[0], y: batch[1]})\n",
    "    if ((i+1)<10 or (i+1)%1000 == 0):\n",
    "        batch_accuracy = accuracy.eval(feed_dict={X: batch[0], y: batch[1]})\n",
    "        print(\"Iteration %s, training accuracy: %s\" % ((i+1), batch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "===== Three-layer Neural Network with (200, 200, 200) hidden units =====\n",
      "========================================================================\n",
      "Training accuracy:\t 99.762 %\n",
      "Testing accuracy:\t 97.740 %\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[ 951    0    3    0    1    7   10    4    1    3]\n",
      " [   0 1122    3    2    0    1    2    1    3    1]\n",
      " [   0    0 1004    9    3    0    2    8    6    0]\n",
      " [   1    0    4  995    0    1    0    4    4    1]\n",
      " [   0    0    4    0  962    1    1    5    1    8]\n",
      " [   3    0    0   11    2  866    5    1    2    2]\n",
      " [   2    3    0    2    5    4  939    3    0    0]\n",
      " [   0    1    6    3    2    0    0 1012    1    3]\n",
      " [   2    0    3    5    1    4    2    4  949    4]\n",
      " [   1    2    1    9   10    1    1    7    3  974]]\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = accuracy.eval(feed_dict={\n",
    "    X: mnist.train.images, \n",
    "    y: mnist.train.labels\n",
    "})*100\n",
    "testing_accuracy = accuracy.eval(feed_dict={\n",
    "    X: mnist.test.images, \n",
    "    y: mnist.test.labels\n",
    "})*100\n",
    "\n",
    "predictions = sess.run(tf.argmax(\n",
    "    tf.nn.softmax(finalOutput), 1\n",
    "), feed_dict={X: mnist.test.images})\n",
    "\n",
    "labels = sess.run(tf.argmax(mnist.test.labels, 1))\n",
    "\n",
    "print(\"========================================================================\")\n",
    "print(\"===== Three-layer Neural Network with (%s, %s, %s) hidden units =====\" % \n",
    "      (numHiddenUnits1, numHiddenUnits2, numHiddenUnits3)\n",
    ")\n",
    "print(\"========================================================================\")\n",
    "print(\"Training accuracy:\\t %.3f %%\" % training_accuracy)\n",
    "print(\"Testing accuracy:\\t %.3f %%\" % testing_accuracy)\n",
    "\n",
    "print(\"\\nConfusion Matrix: \\n\")\n",
    "print(sess.run(tf.confusion_matrix(labels=labels, predictions=predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Logistic regression on the notMNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Logistic regression model on coronary heart disease dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11      1.0     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61      0.0     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28      1.0     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03      1.0     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78      1.0     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"../../../\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data/\")\n",
    "\n",
    "heart_disease = pd.read_csv(os.path.join(DATA_DIR, \"heart.csv\"))\n",
    "heart_disease['famhist'] = heart_disease['famhist'].apply(lambda x: 1.0 if x=='Present' else 0.0)\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heart_disease_data = heart_disease.as_matrix(\n",
    "    ['sbp', 'tobacco', 'ldl', 'adiposity', 'famhist', 'typea', 'obesity', 'alcohol', 'age']\n",
    ")\n",
    "heart_disease_data = normalize(heart_disease_data)\n",
    "\n",
    "heart_disease_target = np.array(\n",
    "    [[0., 1.] if ele==1 else [1., 0.] for ele in heart_disease['chd']], \n",
    "    dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78536336,  0.05890225,  0.02812583,  0.11343592,  0.00490852,\n",
       "        0.24051753,  0.12418558,  0.47710824,  0.25524309])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((462, 9), (462, 2))\n"
     ]
    }
   ],
   "source": [
    "print(heart_disease_data.shape, heart_disease_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    heart_disease_data, \n",
    "    heart_disease_target, \n",
    "    train_size=0.8, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numFeatures = X_train.shape[1]\n",
    "numClasses = y_train.shape[1]\n",
    "\n",
    "numEpochs = 50000\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "y = tf.placeholder(tf.float32, [None, numClasses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([numFeatures, numClasses], stddev=0.1, seed=1))\n",
    "b = tf.Variable(tf.constant(0.1), [numClasses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_prediction = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=y_prediction\n",
    "    )\n",
    ")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training accuracy: 0.365854\n",
      "Iteration 2, training accuracy: 0.639566\n",
      "Iteration 3, training accuracy: 0.639566\n",
      "Iteration 4, training accuracy: 0.639566\n",
      "Iteration 5, training accuracy: 0.639566\n",
      "Iteration 6, training accuracy: 0.639566\n",
      "Iteration 7, training accuracy: 0.639566\n",
      "Iteration 8, training accuracy: 0.639566\n",
      "Iteration 9, training accuracy: 0.639566\n",
      "Iteration 5000, training accuracy: 0.680217\n",
      "Iteration 10000, training accuracy: 0.699187\n",
      "Iteration 15000, training accuracy: 0.712737\n",
      "Iteration 20000, training accuracy: 0.715447\n",
      "Iteration 25000, training accuracy: 0.720867\n",
      "Iteration 30000, training accuracy: 0.715447\n",
      "Iteration 35000, training accuracy: 0.718157\n",
      "Iteration 40000, training accuracy: 0.720867\n",
      "Iteration 45000, training accuracy: 0.720867\n",
      "Iteration 50000, training accuracy: 0.718157\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(numEpochs):\n",
    "    sess.run(optimizer, feed_dict={X: X_train, y: y_train})\n",
    "    if ((i+1)<10 or (i+1)%5000==0):\n",
    "        training_accuracy = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "        print(\"Iteration %s, training accuracy: %s\" % ((i+1), training_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "===== Logistic Regression on coronary heart disease dataset =====\n",
      "=================================================================\n",
      "Training accuracy:\t 71.816 %\n",
      "Testing accuracy:\t 72.043 %\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[58  8]\n",
      " [18  9]]\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = accuracy.eval(feed_dict={\n",
    "    X: X_train, \n",
    "    y: y_train\n",
    "})*100\n",
    "testing_accuracy = accuracy.eval(feed_dict={\n",
    "    X: X_test, \n",
    "    y: y_test\n",
    "})*100\n",
    "\n",
    "predictions = sess.run(tf.argmax(\n",
    "    tf.nn.softmax(y_prediction), 1\n",
    "), feed_dict={X: X_test})\n",
    "\n",
    "labels = sess.run(tf.argmax(y_test, 1))\n",
    "\n",
    "print(\"=================================================================\")\n",
    "print(\"===== Logistic Regression on coronary heart disease dataset =====\")\n",
    "print(\"=================================================================\")\n",
    "print(\"Training accuracy:\\t %.3f %%\" % training_accuracy)\n",
    "print(\"Testing accuracy:\\t %.3f %%\" % testing_accuracy)\n",
    "\n",
    "print(\"\\nConfusion Matrix: \\n\")\n",
    "print(sess.run(tf.confusion_matrix(labels=labels, predictions=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
